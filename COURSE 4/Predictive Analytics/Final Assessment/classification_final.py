# -*- coding: utf-8 -*-
"""Classification Final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RKW-nB9b3q7xnnJSwo2zRGUyfUYhh0Oc
"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score,classification_report
from sklearn.neighbors import KNeighborsClassifier
from sklearn.preprocessing import MinMaxScaler,StandardScaler

#loading dataset
import pandas as pd
df=pd.read_csv("/content/sample_data/penguins_classification.csv")
df.head()

#shape of the dataset
df.shape

#finding null values
df.isnull().sum()

df.dropna(inplace=True)

df.isnull().sum()

#finding duplicate rows
df.duplicated().sum()

df.describe()

#detecting outliers
import seaborn as sns
import matplotlib.pyplot as plt
plt.figure(figsize=(16,7))
sns.boxplot(df)
plt.show()

#detecting outlier
num_col=df.columns[df.dtypes!="object"]
cat_col=df.columns[df.dtypes=="object"]

def remove_out(df1):
	num_col=df1.columns[df1.dtypes!="object"]
	for i in num_col:
		q1=df1[i].quantile(0.25)
		q3=df1[i].quantile(0.75)
		iqr=q3-q1
		med=df1[i].median()
		df1[i]=np.where((df1[i]<q1-1.5*iqr) | (df1[i]>q3+1.5*iqr),med,df1[i])
	return(df1)

outlier1=remove_out(df)
#outliers removed

df.isnull().sum()

#encoding categorical values
from sklearn.preprocessing import LabelEncoder
le=LabelEncoder()
df["species"]=le.fit_transform(df["species"])
df["island"]=le.fit_transform(df["island"])

df.head()

plt.figure(figsize=(15,8))
sns.heatmap(df.corr(),cmap="viridis",annot=True)

df.info()

sns.pairplot(df,y_vars="species")

x=df.drop(columns="species")
y=df["species"]

# Splitting the dataset into training and test set.
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test= train_test_split(x, y, test_size= 0.25, random_state=0)

#feature Scaling
from sklearn.preprocessing import StandardScaler
st_x= StandardScaler()
x_train= st_x.fit_transform(x_train)
x_test= st_x.transform(x_test)

#Fitting Decision Tree classifier to the training set
from sklearn.ensemble import RandomForestClassifier
classifier= RandomForestClassifier(criterion="entropy")
classifier.fit(x_train, y_train)

#Predicting the test set result
y_pred= classifier.predict(x_test)

#Creating the metrics of the model
from sklearn.metrics import accuracy_score,confusion_matrix, classification_report
print("Accuracy Score: ",accuracy_score(y_test,y_pred))
cm= confusion_matrix(y_test, y_pred)
plt.figure(figsize=(10,5))
sns.heatmap(cm,annot=True,cmap="viridis")
plt.plot()
print("Classification Report: ")
print(classification_report(y_test,y_pred))
print("Confusion Matrix")

