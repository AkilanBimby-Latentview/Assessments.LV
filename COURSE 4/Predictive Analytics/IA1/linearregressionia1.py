# -*- coding: utf-8 -*-
"""LinearRegressionIA1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Z36G_7RVOXK0ESnJkOgO4BL1rX34HIfr
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import MinMaxScaler,StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import LabelEncoder
import sklearn.metrics as metrics
from sklearn.metrics import r2_score,mean_squared_error

df=pd.read_csv("/content/sample_data/expenses.csv")
df.head()

df.shape

df.describe()

df.info()

"""1.a"""

#1.a

df.isnull().sum()

bmi_mean = df['bmi'].mean()
print(bmi_mean)
df['bmi'].fillna(bmi_mean,inplace=True)

df.isnull().sum()

df.duplicated().sum()

"""1.b"""

#1.b

#identifying outlier
sns.boxplot(df["age"])
plt.show()
sns.boxplot(df["bmi"])
plt.show()
sns.boxplot(df["children"])
plt.show()
sns.boxplot(df["charges"])
plt.show()

# Calculate Q1, Q3, and IQR
q1 = df['bmi'].quantile(0.25)
q3 = df['bmi'].quantile(0.75)
iqr = q3 - q1

# Calculate outlier bounds
lower_bound = q1 - 1.5 * iqr
upper_bound = q3 + 1.5 * iqr

# Filter dataframe to remove outliers
clean_df = df[(df['bmi'].index >= lower_bound) & (df['bmi'].index <= upper_bound)]

print("DataFrame after removing outliers:")
print(clean_df)

# Plot histograms for numerical columns
for column in df.select_dtypes(include=['float64', 'int64']).columns:
    plt.figure(figsize=(10, 5))
    sns.histplot(df[column])
    plt.title(f'Histogram of {column}')
    plt.xlabel(column)
    plt.ylabel('Frequency')
    plt.show()

"""2."""

#2

# Initialize LabelEncoder
label_encoder = LabelEncoder()
categories = df.select_dtypes(include=['object']).columns

encoded_df=df

# Fit and transform the target column
for column in categories:
    encoded_df[column] = label_encoder.fit_transform(encoded_df[column])
encoded_df

"""3."""

df.duplicated().sum()
df=df.drop_duplicates()



"""4"""



#splitting features and labels
X=df.drop(columns='charges') #feature
y=df["charges"] #label

"""5"""

#splitting train and test dataset
from sklearn.preprocessing import StandardScaler
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)
st_x= StandardScaler()
X_train= st_x.fit_transform(X_train)
X_test= st_x.transform(X_test)
model=LinearRegression()
model.fit(X_train,y_train)
prediction=model.predict(X_test)

"""6"""

from sklearn.metrics import r2_score,mean_squared_error,mean_absolute_error
print("r2_score:",r2_score(y_test,prediction))
print("mean_squared_error:",mean_squared_error(y_test,prediction))
print("mean_absolute_error",mean_absolute_error(y_test,prediction))
print("root_mean_square_eror: ",np.sqrt(mean_squared_error(y_test,prediction)))

plt.scatter(y_test, prediction, c='red', label='Actual')
plt.scatter(y_test,y_test,  c='blue', label='Predicted')
plt.xlabel("Actual values")
plt.ylabel("Predicted values")
plt.plot([min(y_test), max(y_test)], color='black', linestyle='-', label='bestfitline')
plt.legend()

